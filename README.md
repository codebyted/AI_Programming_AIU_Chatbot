# ğŸ“š AIU Assistant â€” PDF-Based AI Chatbot (RAG with Ollama)

AIU Assistant is a **document-grounded AI chatbot** designed to answer questions **strictly from official Africa International University (AIU) PDF documents**.
It uses a **Retrieval-Augmented Generation (RAG)** approach powered by **pdfplumber**, **Streamlit**, and a **local LLM via Ollama (LLaMA 3)**.

> ğŸ›‘ The assistant **never invents answers**. If information is not found in the PDFs, it explicitly says so.

---

## ğŸš€ Key Features

* Reads **multiple PDFs automatically** from a folder
* Splits documents into manageable text chunks
* Keyword-based retrieval (no hallucinations)
* Local LLM inference using **Ollama**
* Strict context enforcement (PDFs only)
* Friendly, student-oriented explanations
* Automatic fallback if LLM fails
* Chat-style interface with typing animation
* Clean AIU-branded dark UI
* No external cloud AI required

---

## ğŸ§  System Architecture (How It Works)

```
User Question
     â†“
Keyword Search over PDF Chunks
     â†“
Top Relevant Chunks (Context)
     â†“
Local LLM (Ollama / LLaMA 3)
     â†“
Answer (STRICTLY from PDFs)
```

If the LLM fails:

```
Fallback â†’ Raw PDF text shown directly
```

---

## ğŸ—‚ï¸ Project Structure

```
aiu-chatbot/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ PDF/                 # Place all AIU PDFs here
â”‚
â”œâ”€â”€ app.py                   # Main Streamlit app
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Documentation
```

---

## ğŸ§© Requirements

### 1ï¸âƒ£ Python Version

* **Python 3.9 â€“ 3.11 (recommended)**

Check:

```bash
python --version
```

---

### 2ï¸âƒ£ System Requirements

| Component | Requirement                      |
| --------- | -------------------------------- |
| OS        | Windows / Linux / macOS          |
| RAM       | 8 GB minimum (16 GB recommended) |
| Disk      | ~5â€“10 GB free                    |
| Internet  | Only needed for initial setup    |
| GPU       | Optional (CPU works fine)        |

---

### 3ï¸âƒ£ Install Ollama (Required)

Ollama runs the LLM locally.

Download and install from:

```
https://ollama.com
```

Verify installation:

```bash
ollama --version
```

Pull the model:

```bash
ollama pull llama3
```

Start Ollama (if not auto-running):

```bash
ollama serve
```

---

## ğŸ“¦ Python Dependencies

### Required Libraries

| Library    | Purpose             |
| ---------- | ------------------- |
| streamlit  | Web UI              |
| pdfplumber | PDF text extraction |
| requests   | LLM API calls       |
| textwrap   | Formatting text     |
| typing     | Type hints          |
| os         | File handling       |

---

### Install Dependencies

```bash
pip install streamlit pdfplumber requests
```

(Optional but recommended)

```bash
pip install python-dotenv
```

---

## â–¶ï¸ Running the Application

From the project root:

```bash
streamlit run app.py
```

Open in browser:

```
http://localhost:8501
```

---

## ğŸ“‚ Adding Documents

1. Place official AIU PDFs inside:

```
data/PDF/
```

2. Restart or refresh the app
3. PDFs are automatically indexed in the background

---

## ğŸ” Retrieval Logic (Important)

* PDFs are split into **900-character chunks**
* No embeddings or vector DB
* Keyword matching only
* Chunks are ranked by query relevance
* Top **4 chunks** are used as context

This guarantees:

* âœ… Transparency
* âœ… No hallucinations
* âŒ Less semantic flexibility than embeddings

---

## ğŸ§  LLM Behavior (Strict Mode)

The LLM is instructed to:

* Use **ONLY provided context**
* Never use outside knowledge
* Never guess or invent
* Respond clearly and politely
* Say *â€œI am not sureâ€* if answer is missing

This makes it **safe for academic and policy use**.

---

## ğŸ›Ÿ Fallback Mechanism

If:

* Ollama is not running
* Model times out
* Network fails

â¡ The app automatically shows **raw PDF excerpts** instead of crashing.

---

## ğŸ’¬ Chat Interface

* Persistent conversation (session-based)
* User and assistant roles
* Typing animation for realism
* AIU-themed styling
* Clean markdown rendering

---

## ğŸ¨ UI & Branding

* Dark academic theme
* AIU red / white / black colors
* Custom CSS injection
* No Streamlit branding
* Sidebar document list

---

## âš ï¸ Limitations

* No semantic embeddings
* No OCR for scanned PDFs
* No authentication
* No cloud deployment by default
* Context window limited to top chunks

---

## ğŸ”® Possible Enhancements

* Add ChromaDB or FAISS embeddings
* Add PDF upload UI
* Add citation highlighting
* Add multi-language support
* Add user roles (student / staff)
* Replace Streamlit with FastAPI + frontend
* Deploy with Docker

---

## ğŸ‘¨â€ğŸ“ Intended Use Cases

* University policy assistant
* Student handbook chatbot
* Academic compliance queries
* Internal knowledge base
* Administrative support tool

---

## ğŸ“œ License

Open-source. Free for educational and internal institutional use.

---

## âœ¨ Author Notes

This project demonstrates:

* Practical RAG without hallucination
* Local LLM deployment
* Safe AI for institutions
* Clean UI/UX for chat systems
* Robust fallback handling

---

### âœ… You now have:

âœ” 3 professional READMEs
âœ” A full data â†’ ML â†’ RAG portfolio
âœ” Exam-ready & GitHub-ready projects

If you want, I can now:
**combine all three into a single portfolio**,
**convert one to FastAPI**, or
**prepare GitHub descriptions + demo videos**.

Just tell me whatâ€™s next ğŸš€
